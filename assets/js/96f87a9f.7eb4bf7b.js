"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[1743],{5786:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>b,contentTitle:()=>j,default:()=>k,frontMatter:()=>f,metadata:()=>y,toc:()=>C});var a=t(5893),n=t(1151),l=t(5316),s=t(4959),i=t(2775),o=t(5488),c=t(5162),d=t(3e3),h=t(9637);const u={code:"import { CheerioCrawler, Dataset } from 'crawlee';\n\n// CheerioCrawler crawls the web using HTTP requests\n// and parses HTML using the Cheerio library.\nconst crawler = new CheerioCrawler({\n    // Use the requestHandler to process each of the crawled pages.\n    async requestHandler({ request, $, enqueueLinks, log }) {\n        const title = $('title').text();\n        log.info(`Title of ${request.loadedUrl} is '${title}'`);\n\n        // Save results as JSON to ./storage/datasets/default\n        await Dataset.pushData({ title, url: request.loadedUrl });\n\n        // Extract links from the current page\n        // and add them to the crawling queue.\n        await enqueueLinks();\n    },\n\n    // Let's limit our crawls to make our tests shorter and safer.\n    maxRequestsPerCrawl: 50,\n});\n\n// Add first URL to the queue and start the crawl.\nawait crawler.run(['https://crawlee.dev']);\n",hash:"invalid-token"},p={code:"import { PlaywrightCrawler, Dataset } from 'crawlee';\n\n// PlaywrightCrawler crawls the web using a headless\n// browser controlled by the Playwright library.\nconst crawler = new PlaywrightCrawler({\n    // Use the requestHandler to process each of the crawled pages.\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        const title = await page.title();\n        log.info(`Title of ${request.loadedUrl} is '${title}'`);\n\n        // Save results as JSON to ./storage/datasets/default\n        await Dataset.pushData({ title, url: request.loadedUrl });\n\n        // Extract links from the current page\n        // and add them to the crawling queue.\n        await enqueueLinks();\n    },\n    // Uncomment this option to see the browser window.\n    // headless: false,\n\n    // Let's limit our crawls to make our tests shorter and safer.\n    maxRequestsPerCrawl: 50,\n});\n\n// Add first URL to the queue and start the crawl.\nawait crawler.run(['https://crawlee.dev']);\n",hash:"invalid-token"},w={code:"import { PlaywrightCrawler, Dataset } from 'crawlee';\n\nconst crawler = new PlaywrightCrawler({\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        const title = await page.title();\n        log.info(`Title of ${request.loadedUrl} is '${title}'`);\n        await Dataset.pushData({ title, url: request.loadedUrl });\n        await enqueueLinks();\n    },\n    // When you turn off headless mode, the crawler\n    // will run with a visible browser window.\n    headless: false,\n\n    // Let's limit our crawls to make our tests shorter and safer.\n    maxRequestsPerCrawl: 50,\n});\n\n// Add first URL to the queue and start the crawl.\nawait crawler.run(['https://crawlee.dev']);\n",hash:"invalid-token"},g={code:"import { PuppeteerCrawler, Dataset } from 'crawlee';\n\n// PuppeteerCrawler crawls the web using a headless\n// browser controlled by the Puppeteer library.\nconst crawler = new PuppeteerCrawler({\n    // Use the requestHandler to process each of the crawled pages.\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        const title = await page.title();\n        log.info(`Title of ${request.loadedUrl} is '${title}'`);\n\n        // Save results as JSON to ./storage/datasets/default\n        await Dataset.pushData({ title, url: request.loadedUrl });\n\n        // Extract links from the current page\n        // and add them to the crawling queue.\n        await enqueueLinks();\n    },\n    // Uncomment this option to see the browser window.\n    // headless: false,\n\n    // Let's limit our crawls to make our tests shorter and safer.\n    maxRequestsPerCrawl: 50,\n});\n\n// Add first URL to the queue and start the crawl.\nawait crawler.run(['https://crawlee.dev']);\n",hash:"invalid-token"},m={code:"import { PuppeteerCrawler, Dataset } from 'crawlee';\n\nconst crawler = new PuppeteerCrawler({\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        const title = await page.title();\n        log.info(`Title of ${request.loadedUrl} is '${title}'`);\n        await Dataset.pushData({ title, url: request.loadedUrl });\n        await enqueueLinks();\n    },\n    // When you turn off headless mode, the crawler\n    // will run with a visible browser window.\n    headless: false,\n\n    // Let's limit our crawls to make our tests shorter and safer.\n    maxRequestsPerCrawl: 50,\n});\n\n// Add first URL to the queue and start the crawl.\nawait crawler.run(['https://crawlee.dev']);\n",hash:"invalid-token"},x="INFO  CheerioCrawler: Starting the crawl\nINFO  CheerioCrawler: Title of https://crawlee.dev/ is 'Crawlee \xb7 Build reliable crawlers. Fast. | Crawlee'\nINFO  CheerioCrawler: Title of https://crawlee.dev/docs/examples is 'Examples | Crawlee'\nINFO  CheerioCrawler: Title of https://crawlee.dev/docs/quick-start is 'Quick Start | Crawlee'\nINFO  CheerioCrawler: Title of https://crawlee.dev/docs/guides is 'Guides | Crawlee'\n",f={id:"quick-start",title:"Quick Start",description:"With this short tutorial you can start scraping with Crawlee in a minute or two. To learn more, read the Introduction."},j=void 0,y={id:"quick-start/quick-start",title:"Quick Start",description:"With this short tutorial you can start scraping with Crawlee in a minute or two. To learn more, read the Introduction.",source:"@site/../docs/quick-start/index.mdx",sourceDirName:"quick-start",slug:"/quick-start/",permalink:"/crawlee-cn/docs/next/quick-start/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"quick-start",title:"Quick Start",description:"With this short tutorial you can start scraping with Crawlee in a minute or two. To learn more, read the Introduction."},sidebar:"docs",next:{title:"Introduction",permalink:"/crawlee-cn/docs/next/introduction/"}},b={},C=[{value:"\u9009\u62e9\u4f60\u7684\u7f51\u7edc\u722c\u866b",id:"\u9009\u62e9\u4f60\u7684\u7f51\u7edc\u722c\u866b",level:2},{value:"CheerioCrawler",id:"cheeriocrawler",level:3},{value:"PuppeteerCrawler",id:"puppeteercrawler",level:3},{value:"PlaywrightCrawler",id:"playwrightcrawler",level:3},{value:"Installation with Crawlee CLI",id:"installation-with-crawlee-cli",level:2},{value:"Manual installation",id:"manual-installation",level:2},{value:"Crawling",id:"crawling",level:2},{value:"Running headful browsers",id:"running-headful-browsers",level:3},{value:"Results",id:"results",level:2},{value:"Examples and further reading",id:"examples-and-further-reading",level:2}];function v(e){const r={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,n.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(r.p,{children:["\u901a\u8fc7\u8fd9\u4e2a\u7b80\u77ed\u7684\u6559\u7a0b\uff0c\u4f60\u53ef\u4ee5\u5728\u4e00\u4e24\u5206\u949f\u5185\u5f00\u59cb\u4f7f\u7528Crawlee\u8fdb\u884c\u722c\u53d6\u3002\u8981\u6df1\u5165\u4e86\u89e3Crawlee\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u8bf7\u9605\u8bfb",(0,a.jsx)(r.a,{href:"./introduction",children:"\u4ecb\u7ecd"}),"\uff0c\u8fd9\u662f\u4e00\u4e2a\u5168\u9762\u7684\u9010\u6b65\u6307\u5357\uff0c\u53ef\u5e2e\u52a9\u4f60\u521b\u5efa\u7b2c\u4e00\u4e2a\u722c\u866b\u3002"]}),"\n",(0,a.jsx)(r.h2,{id:"\u9009\u62e9\u4f60\u7684\u7f51\u7edc\u722c\u866b",children:"\u9009\u62e9\u4f60\u7684\u7f51\u7edc\u722c\u866b"}),"\n",(0,a.jsxs)(r.p,{children:["Crawlee\u6709\u4e09\u4e2a\u4e3b\u8981\u7684\u722c\u866b\u7c7b\uff1a",(0,a.jsx)(s.Z,{to:"cheerio-crawler/class/CheerioCrawler",children:(0,a.jsx)(r.code,{children:"CheerioCrawler"})}),"\uff0c",(0,a.jsx)(s.Z,{to:"puppeteer-crawler/class/PuppeteerCrawler",children:(0,a.jsx)(r.code,{children:"PuppeteerCrawler"})}),"\u548c",(0,a.jsx)(s.Z,{to:"playwright-crawler/class/PlaywrightCrawler",children:(0,a.jsx)(r.code,{children:"PlaywrightCrawler"})}),"\u3002\u6240\u6709\u8fd9\u4e9b\u7c7b\u90fd\u5171\u4eab\u76f8\u540c\u7684\u63a5\u53e3\uff0c\u4ee5\u4fbf\u5728\u5b83\u4eec\u4e4b\u95f4\u8fdb\u884c\u7075\u6d3b\u5207\u6362\u3002"]}),"\n",(0,a.jsx)(r.h3,{id:"cheeriocrawler",children:"CheerioCrawler"}),"\n",(0,a.jsxs)(r.p,{children:["This is a plain HTTP crawler. It parses HTML using the ",(0,a.jsx)(r.a,{href:"https://github.com/cheeriojs/cheerio",target:"_blank",rel:"noopener",children:"Cheerio"})," library and crawls the web using the specialized ",(0,a.jsx)(r.a,{href:"https://github.com/apify/got-scraping",target:"_blank",rel:"noopener",children:"got-scraping"})," HTTP client which masks as a browser. It's very fast and efficient, but can't handle JavaScript rendering."]}),"\n",(0,a.jsx)(r.h3,{id:"puppeteercrawler",children:"PuppeteerCrawler"}),"\n",(0,a.jsxs)(r.p,{children:["\u8fd9\u662f\u4e00\u4e2a\u666e\u901a\u7684HTTP\u722c\u866b\u3002\u5b83\u4f7f\u7528",(0,a.jsx)(r.a,{href:"https://github.com/cheeriojs/cheerio",target:"_blank",rel:"noopener",children:"Cheerio"}),"\u5e93\u89e3\u6790HTML\uff0c\u5e76\u4f7f\u7528\u4e13\u95e8\u7684",(0,a.jsx)(r.a,{href:"https://github.com/apify/got-scraping",target:"_blank",rel:"noopener",children:"got-scraping"})," HTTP\u5ba2\u6237\u7aef\u6765\u722c\u53d6\u7f51\u7edc\uff0c\u8be5\u5ba2\u6237\u7aef\u4f2a\u88c5\u6210\u6d4f\u89c8\u5668\u3002\u5b83\u975e\u5e38\u5feb\u901f\u548c\u9ad8\u6548\uff0c\u4f46\u65e0\u6cd5\u5904\u7406JavaScript\u6e32\u67d3\u3002"]}),"\n",(0,a.jsx)(r.h3,{id:"playwrightcrawler",children:"PlaywrightCrawler"}),"\n",(0,a.jsxs)(r.p,{children:[(0,a.jsx)(r.a,{href:"https://github.com/microsoft/playwright",target:"_blank",rel:"noopener",children:"Playwright"})," is a more powerful and full-featured successor to Puppeteer. It can control Chromium, Chrome, Firefox, Webkit and many other browsers. If you're not familiar with Puppeteer already, and you need a headless browser, go with Playwright."]}),"\n",(0,a.jsx)(r.admonition,{title:"\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u8bf7\u6ce8\u610f",type:"caution",children:(0,a.jsxs)(r.p,{children:["Crawlee \u9700\u8981 ",(0,a.jsx)(r.a,{href:"https://nodejs.org/en/",target:"_blank",rel:"noopener",children:"Node.js 16 \u6216\u66f4\u9ad8\u7248\u672c"}),"\u3002"]})}),"\n",(0,a.jsx)(r.h2,{id:"installation-with-crawlee-cli",children:"Installation with Crawlee CLI"}),"\n",(0,a.jsxs)(r.p,{children:["The fastest way to try Crawlee out is to use the ",(0,a.jsx)(r.strong,{children:"Crawlee CLI"})," and choose the ",(0,a.jsx)(r.strong,{children:"Getting started example"}),".\nThe CLI will install all the necessary dependencies and add boilerplate code for you to play with."]}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-bash",children:"npx crawlee create my-crawler\n"})}),"\n",(0,a.jsx)(r.p,{children:"After the installation is complete you can start the crawler like this:"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-bash",children:"cd my-crawler && npm start\n"})}),"\n",(0,a.jsx)(r.h2,{id:"manual-installation",children:"Manual installation"}),"\n",(0,a.jsx)(r.p,{children:"You can add Crawlee to any Node.js project by running:"}),"\n",(0,a.jsxs)(o.Z,{groupId:"quick_start",children:[(0,a.jsx)(c.Z,{value:"cheerio",label:"CheerioCrawler",default:!0,children:(0,a.jsx)(d.default,{language:"bash",children:"npm install crawlee"})}),(0,a.jsxs)(c.Z,{value:"playwright",label:"PlaywrightCrawler",children:[(0,a.jsx)(r.admonition,{type:"caution",children:(0,a.jsxs)(r.p,{children:[(0,a.jsx)(r.code,{children:"playwright"})," is not bundled with Crawlee to reduce install size and allow greater flexibility. You need to explicitly install it with NPM. \ud83d\udc47"]})}),(0,a.jsx)(d.default,{language:"bash",children:"npm install crawlee playwright"})]}),(0,a.jsxs)(c.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:[(0,a.jsx)(r.admonition,{type:"caution",children:(0,a.jsxs)(r.p,{children:[(0,a.jsx)(r.code,{children:"puppeteer"})," is not bundled with Crawlee to reduce install size and allow greater flexibility. You need to explicitly install it with NPM. \ud83d\udc47"]})}),(0,a.jsx)(d.default,{language:"bash",children:"npm install crawlee puppeteer"})]})]}),"\n",(0,a.jsx)(r.h2,{id:"crawling",children:"Crawling"}),"\n",(0,a.jsx)(r.p,{children:"Run the following example to perform a recursive crawl of the Crawlee website using the selected crawler."}),"\n",(0,a.jsxs)(i.Z,{type:"caution",title:"Don't forget about module imports",children:[(0,a.jsxs)(r.p,{children:["To run the example, add a ",(0,a.jsx)("code",{children:'"type": "module"'})," clause into your"," ","\n",(0,a.jsx)("code",{children:"package.json"})," or copy it into a file with an ",(0,a.jsx)("code",{children:".mjs"})," ","\nsuffix. This enables ",(0,a.jsx)("code",{children:"import"})," statements in Node.js. See"," "]}),(0,a.jsx)("a",{href:"https://nodejs.org/dist/latest-v16.x/docs/api/esm.html#enabling",target:"_blank",rel:"noreferrer",children:(0,a.jsx)(r.p,{children:"Node.js docs"})})," ",(0,a.jsx)(r.p,{children:"for more information."})]}),"\n",(0,a.jsxs)(o.Z,{groupId:"quick_start",children:[(0,a.jsx)(c.Z,{value:"cheerio",label:"CheerioCrawler",default:!0,children:(0,a.jsx)(l.Z,{className:"language-js",type:"cheerio",children:u})}),(0,a.jsx)(c.Z,{value:"playwright",label:"PlaywrightCrawler",children:(0,a.jsx)(l.Z,{className:"language-js",type:"playwright",children:p})}),(0,a.jsx)(c.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:(0,a.jsx)(l.Z,{className:"language-js",type:"puppeteer",children:g})})]}),"\n",(0,a.jsx)(r.p,{children:"When you run the example, you will see Crawlee automating the data extraction process in your terminal."}),"\n",(0,a.jsx)(d.default,{language:"log",children:x}),"\n",(0,a.jsx)(r.h3,{id:"running-headful-browsers",children:"Running headful browsers"}),"\n",(0,a.jsxs)(r.p,{children:["Browsers controlled by Puppeteer and Playwright run headless (without a visible window). You can switch to headful by adding the ",(0,a.jsx)(r.code,{children:"headless: false"})," option to the crawlers' constructor. This is useful in the development phase when you want to see what's going on in the browser."]}),"\n",(0,a.jsxs)(o.Z,{groupId:"quick_start",children:[(0,a.jsx)(c.Z,{value:"playwright",label:"PlaywrightCrawler",children:(0,a.jsx)(l.Z,{className:"language-js",type:"playwright",children:w})}),(0,a.jsx)(c.Z,{value:"puppeteer",label:"PuppeteerCrawler",children:(0,a.jsx)(l.Z,{className:"language-js",type:"puppeteer",children:m})})]}),"\n",(0,a.jsx)(r.p,{children:"When you run the example code, you'll see an automated browser blaze through the Crawlee website."}),"\n",(0,a.jsx)(r.admonition,{type:"note",children:(0,a.jsx)(r.p,{children:"For the sake of this show off, we've slowed down the crawler, but rest assured, it's blazing fast in real world usage."})}),"\n",(0,a.jsx)(h.Z,{alt:"An image showing off Crawlee scraping the Crawlee website using Puppeteer/Playwright and Chromium",sources:{light:"/img/chrome-scrape-light.gif",dark:"/img/chrome-scrape-dark.gif"}}),"\n",(0,a.jsx)(r.h2,{id:"results",children:"Results"}),"\n",(0,a.jsxs)(r.p,{children:["Crawlee stores data to the ",(0,a.jsx)(r.code,{children:"./storage"})," directory in your current working directory. The results of your crawl will be available under ",(0,a.jsx)(r.code,{children:"./storage/datasets/default/*.json"})," as JSON files."]}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-json",metastring:'title="./storage/datasets/default/000000001.json"',children:'{\n    "url": "https://crawlee.dev/",\n    "title": "Crawlee \xb7 The scalable web crawling, scraping and automation library for JavaScript/Node.js | Crawlee"\n}\n'})}),"\n",(0,a.jsx)(r.admonition,{type:"tip",children:(0,a.jsxs)(r.p,{children:["You can override the storage directory by setting the ",(0,a.jsx)(r.code,{children:"CRAWLEE_STORAGE_DIR"})," environment variable."]})}),"\n",(0,a.jsx)(r.h2,{id:"examples-and-further-reading",children:"Examples and further reading"}),"\n",(0,a.jsxs)(r.p,{children:["You can find more examples showcasing various features of Crawlee in the ",(0,a.jsx)(r.a,{href:"./examples",children:"Examples"})," section of the documentation. To better understand Crawlee and its components you should read the ",(0,a.jsx)(r.a,{href:"./introduction",children:"Introduction"})," step-by-step guide."]}),"\n",(0,a.jsx)(r.p,{children:(0,a.jsx)(r.strong,{children:"Related links"})}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"./guides/configuration",children:"Configuration"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"./guides/request-storage",children:"Request storage"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"./guides/result-storage",children:"Result storage"})}),"\n"]})]})}function k(e={}){const{wrapper:r}={...(0,n.a)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(v,{...e})}):v(e)}},4959:(e,r,t)=>{t.d(r,{Z:()=>c});t(7294);var a=t(9960),n=t(4477),l=t(2263),s=t(5893),i=t(643).version.split("."),o=[i[0],i[1]].join(".");const c=function(e){var r=e.to,t=e.children,i=(0,n.E)();return(0,l.default)().siteConfig.presets[0][1].docs.disableVersioning||i.version===o?(0,s.jsx)(a.default,{to:"/api/"+r,children:t}):(0,s.jsx)(a.default,{to:"/api/"+("current"===i.version?"next":i.version)+"/"+r,children:t})}},5316:(e,r,t)=>{t.d(r,{Z:()=>h});var a=t(3366),n=(t(7294),t(512)),l=t(3e3),s=t(9960);const i={button:"button_YBBj",container:"container_TGAW"};var o=t(5893),c=["children","actor","hash","type"],d={playwright:"6i5QsHBMtm3hKph70",puppeteer:"7tWSD8hrYzuc9Lte7",cheerio:"kk67IcZkKSSBTslXI"};const h=function(e){var r,t=e.children,h=e.actor,u=e.hash,p=e.type,w=(0,a.Z)(e,c);if(u=null!=(r=u)?r:t.hash,!t.code)throw new Error('RunnableCodeBlock requires "code" and "hash" props\nMake sure you are importing the code block contents with the roa-loader.');if(!u)return(0,o.jsx)(l.default,Object.assign({},w,{children:t.code}));var g="https://console.apify.com/actors/"+(null!=h?h:d[null!=p?p:"playwright"])+"?runConfig="+u+"&asrc=run_on_apify";return(0,o.jsxs)("div",{className:(0,n.Z)(i.container,"runnable-code-block"),children:[(0,o.jsxs)(s.default,{href:g,className:i.button,rel:"follow",children:["Run on",(0,o.jsxs)("svg",{width:"91",height:"25",viewBox:"0 0 91 25",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"apify-logo-light alignMiddle_src-theme-Footer-index-module",children:[(0,o.jsx)("path",{d:"M3.135 2.85A3.409 3.409 0 0 0 .227 6.699l2.016 14.398 8.483-19.304-7.59 1.059Z",fill:"#97D700"}),(0,o.jsx)("path",{d:"M23.604 14.847 22.811 3.78a3.414 3.414 0 0 0-3.64-3.154c-.077 0-.153.014-.228.025l-3.274.452 7.192 16.124c.54-.67.805-1.52.743-2.379Z",fill:"#71C5E8"}),(0,o.jsx)("path",{d:"M5.336 24.595c.58.066 1.169-.02 1.706-.248l12.35-5.211L13.514 5.97 5.336 24.595Z",fill:"#FF9013"}),(0,o.jsx)("path",{d:"M33.83 5.304h3.903l5.448 14.623h-3.494l-1.022-2.994h-5.877l-1.025 2.994h-3.384L33.83 5.304Zm-.177 9.032h4.14l-2-5.994h-.086l-2.054 5.994ZM58.842 5.304h3.302v14.623h-3.302V5.304ZM64.634 5.304h10.71v2.7h-7.4v4.101h5.962v2.632h-5.963v5.186h-3.309V5.303ZM82.116 14.38l-5.498-9.076h3.748l3.428 6.016h.085l3.599-6.016H91l-5.56 9.054v5.569h-3.324v-5.548ZM51.75 5.304h-7.292v14.623h3.3v-4.634h3.993a4.995 4.995 0 1 0 0-9.99Zm-.364 7.417h-3.628V7.875h3.627a2.423 2.423 0 0 1 0 4.846Z",className:"apify-logo",fill:"#000"})]})]}),(0,o.jsx)(l.default,Object.assign({},w,{className:(0,n.Z)(i.codeBlock,"code-block",null!=w.title?"has-title":"no-title"),children:t.code}))]})}},643:e=>{e.exports=JSON.parse('{"name":"crawlee","version":"3.6.2","description":"The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.","engines":{"node":">=16.0.0"},"bin":"./src/cli.ts","main":"./dist/index.js","module":"./dist/index.mjs","types":"./dist/index.d.ts","exports":{".":{"import":"./dist/index.mjs","require":"./dist/index.js","types":"./dist/index.d.ts"},"./package.json":"./package.json"},"keywords":["apify","headless","chrome","puppeteer","crawler","scraper"],"author":{"name":"Apify","email":"support@apify.com","url":"https://apify.com"},"contributors":["Jan Curn <jan@apify.com>","Marek Trunkat <marek@apify.com>","Ondra Urban <ondra@apify.com>"],"license":"Apache-2.0","repository":{"type":"git","url":"git+https://github.com/apify/crawlee"},"bugs":{"url":"https://github.com/apify/crawlee/issues"},"homepage":"https://crawlee.dev","scripts":{"build":"yarn clean && yarn compile && yarn copy","clean":"rimraf ./dist","compile":"tsc -p tsconfig.build.json && gen-esm-wrapper ./dist/index.js ./dist/index.mjs","copy":"tsx ../../scripts/copy.ts"},"publishConfig":{"access":"public"},"dependencies":{"@crawlee/basic":"3.6.2","@crawlee/browser":"3.6.2","@crawlee/browser-pool":"3.6.2","@crawlee/cheerio":"3.6.2","@crawlee/cli":"3.6.2","@crawlee/core":"3.6.2","@crawlee/http":"3.6.2","@crawlee/jsdom":"3.6.2","@crawlee/linkedom":"3.6.2","@crawlee/playwright":"3.6.2","@crawlee/puppeteer":"3.6.2","@crawlee/utils":"3.6.2","import-local":"^3.1.0","tslib":"^2.4.0"},"peerDependencies":{"playwright":"*","puppeteer":"*"},"peerDependenciesMeta":{"playwright":{"optional":true},"puppeteer":{"optional":true}}}')}}]);