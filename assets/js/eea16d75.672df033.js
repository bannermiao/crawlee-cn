"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[4586],{8927:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>t,metadata:()=>d,toc:()=>c});var o=r(5893),s=r(1151);const t={id:"got-scraping",title:"Got Scraping",description:"Blazing fast cURL alternative for modern web scraping"},i=void 0,d={id:"guides/got-scraping",title:"Got Scraping",description:"Blazing fast cURL alternative for modern web scraping",source:"@site/../docs/guides/got_scraping.mdx",sourceDirName:"guides",slug:"/guides/got-scraping",permalink:"/docs/next/guides/got-scraping",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"got-scraping",title:"Got Scraping",description:"Blazing fast cURL alternative for modern web scraping"},sidebar:"docs",previous:{title:"JSDOMCrawler",permalink:"/docs/next/guides/jsdom-crawler-guide"},next:{title:"TypeScript Projects",permalink:"/docs/next/guides/typescript-project"}},a={},c=[{value:"Intro",id:"intro",level:2},{value:"<code>sendRequest</code> API",id:"sendrequest-api",level:2},{value:"<code>url</code>",id:"url",level:3},{value:"<code>method</code>",id:"method",level:3},{value:"<code>body</code>",id:"body",level:3},{value:"<code>headers</code>",id:"headers",level:3},{value:"<code>proxyUrl</code>",id:"proxyurl",level:3},{value:"<code>sessionToken</code>",id:"sessiontoken",level:3},{value:"<code>responseType</code>",id:"responsetype",level:3},{value:"<code>cookieJar</code>",id:"cookiejar",level:3},{value:"<code>retry.limit</code>",id:"retrylimit",level:3},{value:"<code>useHeaderGenerator</code>",id:"useheadergenerator",level:3},{value:"<code>headerGeneratorOptions</code>",id:"headergeneratoroptions",level:3}];function l(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"intro",children:"Intro"}),"\n",(0,o.jsxs)(n.p,{children:["When using ",(0,o.jsx)(n.code,{children:"BasicCrawler"}),", we have to send the requests manually. In order to do this, we can use the context-aware ",(0,o.jsx)(n.code,{children:"sendRequest()"})," function:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { BasicCrawler } from 'crawlee';\n\nconst crawler = new BasicCrawler({\n    async requestHandler({ sendRequest, log }) {\n        const res = await sendRequest();\n        log.info('received body', res.body);\n    },\n});\n"})}),"\n",(0,o.jsxs)(n.p,{children:["It uses ",(0,o.jsx)(n.a,{href:"https://github.com/apify/got-scraping",target:"_blank",rel:"noopener",children:(0,o.jsx)(n.code,{children:"got-scraping"})})," under the hood.\nGot Scraping is a ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got",target:"_blank",rel:"noopener",children:"Got"})," extension developed to mimic browser requests, so there's a high chance we'll open the webpage without getting blocked."]}),"\n",(0,o.jsxs)(n.h2,{id:"sendrequest-api",children:[(0,o.jsx)(n.code,{children:"sendRequest"})," API"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"async sendRequest(overrideOptions?: GotOptionsInit) => {\n    return gotScraping({\n        url: request.url,\n        method: request.method,\n        body: request.payload,\n        headers: request.headers,\n        proxyUrl: crawlingContext.proxyInfo?.url,\n        sessionToken: session,\n        responseType: 'text',\n        ...overrideOptions,\n        retry: {\n            limit: 0,\n            ...overrideOptions?.retry,\n        },\n        cookieJar: {\n            getCookieString: (url: string) => session!.getCookieString(url),\n            setCookie: (rawCookie: string, url: string) => session!.setCookie(rawCookie, url),\n            ...overrideOptions?.cookieJar,\n        },\n    });\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"url",children:(0,o.jsx)(n.code,{children:"url"})}),"\n",(0,o.jsxs)(n.p,{children:["By default, it's the URL of current task. However you can override this with a ",(0,o.jsx)(n.code,{children:"string"})," or a ",(0,o.jsx)(n.code,{children:"URL"})," instance if necessary."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#url",target:"_blank",rel:"noopener",children:"Got documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"method",children:(0,o.jsx)(n.code,{children:"method"})}),"\n",(0,o.jsxs)(n.p,{children:["By default, it's the HTTP method of current task. Possible values are ",(0,o.jsx)(n.code,{children:"'GET', 'POST', 'HEAD', 'PUT', 'PATCH', 'DELETE'"}),"."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#method",target:"_blank",rel:"noopener",children:"Got documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"body",children:(0,o.jsx)(n.code,{children:"body"})}),"\n",(0,o.jsx)(n.p,{children:"By default, it's the HTTP payload of current task."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#body",target:"_blank",rel:"noopener",children:"Got documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"headers",children:(0,o.jsx)(n.code,{children:"headers"})}),"\n",(0,o.jsxs)(n.p,{children:["By default, it's the HTTP headers of current task. It's an object with ",(0,o.jsx)(n.code,{children:"string"})," values."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#headers",target:"_blank",rel:"noopener",children:"Got documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"proxyurl",children:(0,o.jsx)(n.code,{children:"proxyUrl"})}),"\n",(0,o.jsxs)(n.p,{children:["It's a string representing the proxy server in the format of ",(0,o.jsx)(n.code,{children:"protocol://username:password@hostname:port"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["For example, an Apify proxy server looks like this: ",(0,o.jsx)(n.code,{children:"http://auto:password@proxy.apify.com:8000"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Basic Crawler does not have the concept of a session or proxy, therefore we need to manually pass the ",(0,o.jsx)(n.code,{children:"proxyUrl"})," option:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { BasicCrawler } from 'crawlee';\n\nconst crawler = new BasicCrawler({\n    async requestHandler({ sendRequest, log }) {\n        const res = await sendRequest({\n            proxyUrl: 'http://auto:password@proxy.apify.com:8000',\n        });\n        log.info('received body', res.body);\n    },\n});\n"})}),"\n",(0,o.jsx)(n.p,{children:"We use proxies to hide our real IP address."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/apify/got-scraping#proxyurl",target:"_blank",rel:"noopener",children:"Got Scraping documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"sessiontoken",children:(0,o.jsx)(n.code,{children:"sessionToken"})}),"\n",(0,o.jsxs)(n.p,{children:["It's a non-primitive object used as a key when generating browser fingerprint. Fingerprints with the same token don't change.\nThis can be used to retain the ",(0,o.jsx)(n.code,{children:"user-agent"})," header when using the same Apify Session."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/apify/got-scraping#sessiontoken",target:"_blank",rel:"noopener",children:"Got Scraping documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"responsetype",children:(0,o.jsx)(n.code,{children:"responseType"})}),"\n",(0,o.jsx)(n.p,{children:"This option defines how the response should be parsed."}),"\n",(0,o.jsxs)(n.p,{children:["By default, we fetch HTML websites - that is plaintext. Hence, we set ",(0,o.jsx)(n.code,{children:"responseType"})," to ",(0,o.jsx)(n.code,{children:"'text'"}),". However, JSON is possible as well:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { BasicCrawler } from 'crawlee';\n\nconst crawler = new BasicCrawler({\n    async requestHandler({ sendRequest, log }) {\n        const res = await sendRequest({ responseType: 'json' });\n        log.info('received body', res.body);\n    },\n});\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#responsetype",target:"_blank",rel:"noopener",children:"Got documentation"}),"."]})}),"\n",(0,o.jsx)(n.h3,{id:"cookiejar",children:(0,o.jsx)(n.code,{children:"cookieJar"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"Got"})," uses a ",(0,o.jsx)(n.code,{children:"cookieJar"})," to manage cookies. It's an object with an interface of a ",(0,o.jsxs)(n.a,{href:"https://github.com/salesforce/tough-cookie",target:"_blank",rel:"noopener",children:[(0,o.jsx)(n.code,{children:"tough-cookie"})," package"]}),"."]}),"\n",(0,o.jsx)(n.p,{children:"Example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { BasicCrawler } from 'crawlee';\nimport { CookieJar } from 'tough-cookie';\n\nconst cookieJar = new CookieJar();\n\nconst crawler = new BasicCrawler({\n    async requestHandler({ sendRequest, log }) {\n        const res = await sendRequest({ cookieJar });\n        log.info('received body', res.body);\n    },\n});\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"More details in"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.em,{children:(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got/blob/main/documentation/2-options.md#cookiejar",target:"_blank",rel:"noopener",children:"Got documentation"})})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.em,{children:(0,o.jsx)(n.a,{href:"https://github.com/salesforce/tough-cookie#cookiejarstore-options",target:"_blank",rel:"noopener",children:"Tough Cookie documentation"})})}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"retrylimit",children:(0,o.jsx)(n.code,{children:"retry.limit"})}),"\n",(0,o.jsxs)(n.p,{children:["This option specifies the maximum number of ",(0,o.jsx)(n.code,{children:"Got"})," retries."]}),"\n",(0,o.jsxs)(n.p,{children:["By default, ",(0,o.jsx)(n.code,{children:"retry.limit"})," is set to ",(0,o.jsx)(n.code,{children:"0"}),". This is because Crawlee has its own (complicated enough) retry management."]}),"\n",(0,o.jsx)(n.p,{children:"We suggest NOT changing this value for stability reasons."}),"\n",(0,o.jsx)(n.h3,{id:"useheadergenerator",children:(0,o.jsx)(n.code,{children:"useHeaderGenerator"})}),"\n",(0,o.jsxs)(n.p,{children:["It's a boolean for whether to generate browser headers. By default, it's set to ",(0,o.jsx)(n.code,{children:"true"}),", and we recommend keeping this for better results."]}),"\n",(0,o.jsx)(n.h3,{id:"headergeneratoroptions",children:(0,o.jsx)(n.code,{children:"headerGeneratorOptions"})}),"\n",(0,o.jsx)(n.p,{children:"This option represents an object how to generate browser fingerprint. Example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"import { BasicCrawler } from 'crawlee';\n\nconst crawler = new BasicCrawler({\n    async requestHandler({ sendRequest, log }) {\n        const res = await sendRequest({\n            headerGeneratorOptions: {\n                devices: ['mobile', 'desktop'],\n                locales: ['en-US'],\n                operatingSystems: ['windows', 'macos', 'android', 'ios'],\n                browsers: ['chrome', 'edge', 'firefox', 'safari'],\n            },\n        });\n        log.info('received body', res.body);\n    },\n});\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["More details in ",(0,o.jsxs)(n.a,{href:"https://apify.github.io/fingerprint-suite/api/fingerprint-generator/interface/HeaderGeneratorOptions/",target:"_blank",rel:"noopener",children:[(0,o.jsx)(n.code,{children:"HeaderGeneratorOptions"})," documentation"]}),"."]})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Related links"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://github.com/sindresorhus/got#documentation",target:"_blank",rel:"noopener",children:"Got documentation"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://github.com/apify/got-scraping",target:"_blank",rel:"noopener",children:"Got Scraping documentation"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://apify.github.io/fingerprint-suite/docs/guides/fingerprint-generator/",target:"_blank",rel:"noopener",children:"Header Generator documentation"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},1151:(e,n,r)=>{r.d(n,{Z:()=>d,a:()=>i});var o=r(7294);const s={},t=o.createContext(s);function i(e){const n=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);